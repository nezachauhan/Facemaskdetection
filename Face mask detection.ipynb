{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as k\n",
    "from keras.layers import Conv2D,MaxPooling2D,SpatialDropout2D,Flatten,Dropout,Dense,BatchNormalization\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.optimizers import adam\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import datetime\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1314 images belonging to 2 classes.\n",
      "Found 194 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "83/83 [==============================] - 41s 495ms/step - loss: 0.7070 - accuracy: 0.8699 - val_loss: 0.4175 - val_accuracy: 0.9588\n",
      "Epoch 2/10\n",
      "83/83 [==============================] - 39s 471ms/step - loss: 0.0947 - accuracy: 0.9642 - val_loss: 0.0580 - val_accuracy: 0.9794\n",
      "Epoch 3/10\n",
      "83/83 [==============================] - 38s 463ms/step - loss: 0.0602 - accuracy: 0.9787 - val_loss: 0.0658 - val_accuracy: 0.9639\n",
      "Epoch 4/10\n",
      "83/83 [==============================] - 38s 461ms/step - loss: 0.0567 - accuracy: 0.9833 - val_loss: 0.0189 - val_accuracy: 0.9639\n",
      "Epoch 5/10\n",
      "83/83 [==============================] - 39s 464ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.5326 - val_accuracy: 0.9330\n",
      "Epoch 6/10\n",
      "83/83 [==============================] - 39s 464ms/step - loss: 0.0320 - accuracy: 0.9901 - val_loss: 6.9000e-04 - val_accuracy: 0.9330\n",
      "Epoch 7/10\n",
      "83/83 [==============================] - 39s 465ms/step - loss: 0.0331 - accuracy: 0.9901 - val_loss: 1.5507e-04 - val_accuracy: 0.9691\n",
      "Epoch 8/10\n",
      "83/83 [==============================] - 38s 462ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 9.9748e-06 - val_accuracy: 0.9794\n",
      "Epoch 9/10\n",
      "83/83 [==============================] - 39s 466ms/step - loss: 0.0383 - accuracy: 0.9848 - val_loss: 8.2781e-05 - val_accuracy: 0.9639\n",
      "Epoch 10/10\n",
      "83/83 [==============================] - 39s 465ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 7.0887e-05 - val_accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "# creating sequential model for our data\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',kernel_initializer = 'he_uniform',input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),activation='relu',kernel_initializer = 'he_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),activation='relu',kernel_initializer = 'he_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(32,(3,3),activation='relu',kernel_initializer = 'he_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "# compile our model with appropriate hyper paarameters\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# Creating generator for our training and testing dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(150,150),\n",
    "        batch_size=16 ,\n",
    "        class_mode='binary')\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(150,150),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "# fitting the dataset to our model with 10 epochs\n",
    "model_saved=model.fit_generator(\n",
    "        training_set,\n",
    "        epochs=10,\n",
    "        validation_data=test_set,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To test for individual images: 0 means person is wearing mask in the image/ 1 means person is not wearing mask.\n",
    "test_image=image.load_img(r'C:\\Users\\tanya\\Desktop\\ml2\\Project\\data\\test\\with_mask\\5-with-mask.jpg',\n",
    "                          target_size=(150,150,3))\n",
    "test_image\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "model.predict_classes(test_image)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam module\n",
    "video_capture=cv2.VideoCapture(0)\n",
    "# detection of face using pre trained model\n",
    "face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# Webcam will start capturing all frames\n",
    "while video_capture.isOpened():\n",
    "    _,img=video_capture.read()\n",
    "    # detection of face with defined hyper parameters\n",
    "    face=face_cascade.detectMultiScale(img,scaleFactor=1.1,minNeighbors=4)\n",
    "    for(x,y,w,h) in face:\n",
    "        face_img = img[y:y+h, x:x+w]\n",
    "        #Set webcam window name as temp.jpg\n",
    "        cv2.imwrite('temp.jpg',face_img)\n",
    "        test_image=image.load_img('temp.jpg',target_size=(150,150,3))\n",
    "        # predicting whether face is covered with mask or not\n",
    "        test_image=image.img_to_array(test_image)\n",
    "        test_image=np.expand_dims(test_image,axis=0)\n",
    "        pred=model.predict_classes(test_image)[0][0]\n",
    "        # if predition is 1 it will show face with red rectangle stating not wearing mask\n",
    "        if pred==1:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "            cv2.putText(img,'NOT WEARING MASK',((x+w)//2,y+h+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "        # if predition is 0 it will show face with green rectangle stating wearing mask\n",
    "        else:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "            cv2.putText(img,'WAERING MASK',((x+w)//2,y+h+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),3)\n",
    "        datet=str(datetime.datetime.now())\n",
    "        cv2.putText(img,datet,(400,450),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1)\n",
    "          \n",
    "    cv2.imshow('video',img)\n",
    "    #Stop capturing frames when pressing 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "        break\n",
    "    \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
